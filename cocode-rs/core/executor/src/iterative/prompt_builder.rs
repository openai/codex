//! Prompt builder for iterative execution with context injection.
//!
//! Implements Auto-Coder style git-based iterative improvement prompts.

use super::context::IterationContext;

/// Default loop instruction appended to queries after first iteration.
const DEFAULT_LOOP_INSTRUCTION: &str = r#"
Additional instruction: use git log to get the code changes generated by previous
tasks and try to focus on iterative improvements and refinements and make sure to
use git commit command to make a commit after every single file edit."#;

/// Complexity assessment prompt - injected on each iteration to guide planning decisions.
const COMPLEXITY_ASSESSMENT_PROMPT: &str = r#"<task_assessment>
## Task Complexity Assessment

Before working on this iteration, evaluate the task complexity:

1. **Complexity Check**:
   - Is this a multi-file change? (3+ files)
   - Does it require understanding existing architecture?
   - Could changes break existing functionality?

2. **Decision**:
   - If complex -> Use `EnterPlanMode` to explore the codebase and plan first
   - If simple -> Proceed directly with implementation

3. **When in Plan Mode**:
   - Explore the codebase to understand patterns and architecture
   - Write your plan to the plan file
   - Call `ExitPlanMode` when ready to implement

Note: EnterPlanMode and ExitPlanMode are auto-approved in this context.
</task_assessment>
"#;

/// Loop context template for enhanced prompts.
const LOOP_CONTEXT_TEMPLATE: &str = r#"<task_context>
## Original Task
{initial_prompt}

{plan_section}## Progress
Iteration: {current} of {total}
Base commit: {base_commit_id}

## Previous Iterations
{iteration_records}
</task_context>

IMPORTANT:
- DO NOT run git commit yourself - the system handles commits automatically
- Focus on making improvements and refinements based on previous work
- You can use git diff/log to review detailed changes if needed
- Each iteration should build upon the previous ones
"#;

/// Plan section template.
const PLAN_SECTION_TEMPLATE: &str = r#"## Plan
{plan_content}

"#;

/// Iteration record template.
const ITERATION_RECORD_TEMPLATE: &str = r#"### Iteration {iteration} -> {commit_status}
Files: {files}
Summary: {summary}
"#;

/// Builder for loop iteration prompts.
///
/// Supports two modes:
/// - Basic mode: just appends loop instruction for iterations > 0
/// - Context passing mode: injects full context block with history
pub struct IterativePromptBuilder {
    /// Original user prompt.
    initial_prompt: String,
    /// Custom loop instruction (overrides default).
    custom_loop_instruction: Option<String>,
    /// Enable complexity assessment prompt injection.
    enable_complexity_assessment: bool,
}

impl IterativePromptBuilder {
    /// Create a new builder with the initial prompt.
    pub fn new(initial_prompt: impl Into<String>) -> Self {
        Self {
            initial_prompt: initial_prompt.into(),
            custom_loop_instruction: None,
            enable_complexity_assessment: true,
        }
    }

    /// Set custom loop instruction (instead of default git-based prompt).
    pub fn with_custom_instruction(mut self, instruction: impl Into<String>) -> Self {
        self.custom_loop_instruction = Some(instruction.into());
        self
    }

    /// Disable complexity assessment prompt injection.
    pub fn without_complexity_assessment(mut self) -> Self {
        self.enable_complexity_assessment = false;
        self
    }

    /// Build prompt for given iteration.
    ///
    /// - Iteration 0: returns original prompt (optionally with complexity assessment)
    /// - Iteration 1+: appends loop instruction
    pub fn build(&self, iteration: i32) -> String {
        if iteration == 0 {
            if self.enable_complexity_assessment {
                format!("{COMPLEXITY_ASSESSMENT_PROMPT}\n{}", self.initial_prompt)
            } else {
                self.initial_prompt.clone()
            }
        } else {
            self.build_enhanced(iteration)
        }
    }

    /// Build prompt with context injection (for context passing mode).
    ///
    /// - Iteration 0: original prompt + complexity assessment
    /// - Iteration 1+: context block + complexity assessment + original prompt
    pub fn build_with_context(&self, iteration: i32, context: &IterationContext) -> String {
        if iteration == 0 {
            return self.build(0);
        }

        // Build plan section
        let plan_section = match &context.plan_content {
            Some(plan) => PLAN_SECTION_TEMPLATE.replace("{plan_content}", plan),
            None => String::new(),
        };

        // Build iteration records
        let iteration_records: String = context
            .iterations
            .iter()
            .map(|record| {
                ITERATION_RECORD_TEMPLATE
                    .replace("{iteration}", &record.iteration.to_string())
                    .replace("{commit_status}", &record.commit_status())
                    .replace("{files}", &record.files_display())
                    .replace("{summary}", &record.summary)
            })
            .collect::<Vec<_>>()
            .join("\n");

        // Format total
        let total_str = if context.total_iterations > 0 {
            context.total_iterations.to_string()
        } else {
            "ongoing".to_string()
        };

        // Build context block
        let base_commit = context.base_commit_id.as_deref().unwrap_or("unknown");
        let context_block = LOOP_CONTEXT_TEMPLATE
            .replace("{initial_prompt}", &context.initial_prompt)
            .replace("{plan_section}", &plan_section)
            .replace("{current}", &(iteration + 1).to_string()) // 1-indexed for display
            .replace("{total}", &total_str)
            .replace("{base_commit_id}", base_commit)
            .replace("{iteration_records}", &iteration_records);

        // Build final prompt
        if self.enable_complexity_assessment {
            format!(
                "{context_block}\n{COMPLEXITY_ASSESSMENT_PROMPT}\n{}",
                self.initial_prompt
            )
        } else {
            format!("{context_block}\n{}", self.initial_prompt)
        }
    }

    /// Build enhanced prompt for iterations > 0 (basic mode).
    fn build_enhanced(&self, _iteration: i32) -> String {
        let instruction = self
            .custom_loop_instruction
            .as_deref()
            .unwrap_or(DEFAULT_LOOP_INSTRUCTION);

        if self.enable_complexity_assessment {
            format!(
                "{COMPLEXITY_ASSESSMENT_PROMPT}\n{}\n\n{instruction}",
                self.initial_prompt
            )
        } else {
            format!("{}\n\n{instruction}", self.initial_prompt)
        }
    }

    /// Get the initial prompt.
    pub fn initial_prompt(&self) -> &str {
        &self.initial_prompt
    }
}

/// Static helper for basic prompt enhancement (backward compat).
pub fn enhance_prompt(original: &str, iteration: i32) -> String {
    IterativePromptBuilder::new(original)
        .without_complexity_assessment()
        .build(iteration)
}

/// Static helper for prompt with custom instruction.
pub fn enhance_prompt_with_custom(
    original: &str,
    iteration: i32,
    custom_instruction: Option<&str>,
) -> String {
    let mut builder = IterativePromptBuilder::new(original).without_complexity_assessment();
    if let Some(instruction) = custom_instruction {
        builder = builder.with_custom_instruction(instruction);
    }
    builder.build(iteration)
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::iterative::context::IterationRecord;

    #[test]
    fn test_first_iteration_with_assessment() {
        let builder = IterativePromptBuilder::new("Implement user auth");
        let result = builder.build(0);

        assert!(result.contains("<task_assessment>"));
        assert!(result.contains("Implement user auth"));
        assert!(result.contains("EnterPlanMode"));
    }

    #[test]
    fn test_first_iteration_without_assessment() {
        let builder =
            IterativePromptBuilder::new("Implement user auth").without_complexity_assessment();
        let result = builder.build(0);

        assert!(!result.contains("<task_assessment>"));
        assert_eq!(result, "Implement user auth");
    }

    #[test]
    fn test_subsequent_iterations_enhanced() {
        let builder =
            IterativePromptBuilder::new("Implement user auth").without_complexity_assessment();
        let result = builder.build(1);

        assert!(result.contains("Implement user auth"));
        assert!(result.contains("git log"));
        assert!(result.contains("iterative improvements"));
    }

    #[test]
    fn test_custom_instruction() {
        let builder = IterativePromptBuilder::new("Fix tests")
            .without_complexity_assessment()
            .with_custom_instruction("Focus on edge cases and error handling");
        let result = builder.build(1);

        assert!(result.contains("Fix tests"));
        assert!(result.contains("Focus on edge cases"));
        assert!(!result.contains("git log")); // No default instruction
    }

    #[test]
    fn test_build_with_context_first_iteration() {
        let builder = IterativePromptBuilder::new("Do the task");
        let ctx = IterationContext::with_context_passing(
            "abc123".to_string(),
            "Implement X".to_string(),
            None,
            5,
        );
        let result = builder.build_with_context(0, &ctx);

        // First iteration includes complexity assessment prompt
        assert!(result.contains("<task_assessment>"));
        assert!(result.contains("Task Complexity Assessment"));
        assert!(result.contains("EnterPlanMode"));
        assert!(result.contains("Do the task"));
    }

    #[test]
    fn test_build_with_context_with_history() {
        let builder = IterativePromptBuilder::new("Continue work");
        let mut ctx = IterationContext::with_context_passing(
            "abc123".to_string(),
            "Implement X".to_string(),
            Some("## Plan\n1. Step one".to_string()),
            5,
        );
        ctx.add_iteration(IterationRecord::with_git_info(
            0,
            "Done step one".to_string(),
            1000,
            Some("def456789".to_string()),
            vec!["file.rs".to_string()],
            "Did step one".to_string(),
            true,
        ));

        let result = builder.build_with_context(1, &ctx);

        assert!(result.contains("<task_context>"));
        assert!(result.contains("## Original Task"));
        assert!(result.contains("Implement X"));
        assert!(result.contains("## Plan"));
        assert!(result.contains("Step one"));
        assert!(result.contains("Iteration: 2 of 5"));
        assert!(result.contains("Base commit: abc123"));
        assert!(result.contains("### Iteration 0"));
        assert!(result.contains("commit def4567"));
        assert!(result.contains("file.rs"));
        assert!(result.contains("Did step one"));
        assert!(result.contains("DO NOT run git commit"));
        assert!(result.contains("Continue work"));
        // Complexity assessment should also be present
        assert!(result.contains("<task_assessment>"));
        assert!(result.contains("EnterPlanMode"));
    }

    #[test]
    fn test_build_with_context_duration_mode() {
        let builder = IterativePromptBuilder::new("Keep going");
        let ctx = IterationContext::with_context_passing(
            "abc123".to_string(),
            "Long task".to_string(),
            None,
            -1, // Duration mode
        );

        let result = builder.build_with_context(1, &ctx);
        assert!(result.contains("Iteration: 2 of ongoing"));
    }

    #[test]
    fn test_build_with_context_no_plan() {
        let builder = IterativePromptBuilder::new("Work");
        let ctx = IterationContext::with_context_passing(
            "abc123".to_string(),
            "Task without plan".to_string(),
            None,
            3,
        );

        let result = builder.build_with_context(1, &ctx);
        assert!(!result.contains("## Plan"));
        assert!(result.contains("## Original Task"));
    }

    #[test]
    fn test_enhance_prompt_static() {
        let result = enhance_prompt("Test prompt", 0);
        assert_eq!(result, "Test prompt");

        let result = enhance_prompt("Test prompt", 1);
        assert!(result.contains("Test prompt"));
        assert!(result.contains("git log"));
    }

    #[test]
    fn test_enhance_prompt_with_custom_static() {
        let result = enhance_prompt_with_custom("Test", 1, Some("Custom instruction"));
        assert!(result.contains("Test"));
        assert!(result.contains("Custom instruction"));
        assert!(!result.contains("git log"));

        let result = enhance_prompt_with_custom("Test", 1, None);
        assert!(result.contains("git log"));
    }
}
